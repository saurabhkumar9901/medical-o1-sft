{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "import requests\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(\n",
    "    api_key=\"AIzaSyDQwvr8L4VlPu38g89AtXTGtfCjhb9lSck\",\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API Key exists\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")\n",
    "    \n",
    "genai.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Geolocation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"AIzaSyANBH1QI59R-dsLFgoOL72S4cQT7vLsdJQ\"\n",
    "\n",
    "def get_location():\n",
    "    url = f\"https://www.googleapis.com/geolocation/v1/geolocate?key={API_KEY}\"\n",
    "    payload = {\"considerIp\": True}\n",
    "    response = requests.post(url, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data[\"location\"][\"lat\"], data[\"location\"][\"lng\"]\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Places API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearby_places(lat, lng, place_type=\"hospital\", radius=5000):\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "    params = {\n",
    "        \"location\": f\"{lat},{lng}\",\n",
    "        \"radius\": radius,\n",
    "        \"type\": place_type,\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"results\", [])\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Distance Matrix API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_travel_time(origin_lat, origin_lng, dest_lat, dest_lng):\n",
    "    \n",
    "    url = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n",
    "    params = {\n",
    "        \"origins\": f\"{origin_lat},{origin_lng}\",\n",
    "        \"destinations\": f\"{dest_lat},{dest_lng}\",\n",
    "        \"mode\": \"driving\",\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        try:\n",
    "            duration = data[\"rows\"][0][\"elements\"][0][\"duration\"][\"text\"]\n",
    "            distance = data[\"rows\"][0][\"elements\"][0][\"distance\"][\"text\"]\n",
    "            return duration, distance\n",
    "        except (IndexError, KeyError):\n",
    "            return \"N/A\", \"N/A\"\n",
    "    return \"N/A\", \"N/A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our location and places function combines all three above API into one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_and_places(place_types=[\"hospital\", \"pharmacy\", \"urgent_care\"], radius=5000):\n",
    "    location = get_location()\n",
    "    if not location:\n",
    "        return \"‚ùå Error fetching location.\"\n",
    "\n",
    "    lat, lng = location\n",
    "    place_details = []\n",
    "\n",
    "    for place_type in place_types:\n",
    "        places = get_nearby_places(lat, lng, place_type, radius)\n",
    "        \n",
    "        for place in places[:3]:  # Show only top 3 results per category\n",
    "            name = place[\"name\"]\n",
    "            rating = place.get(\"rating\", \"N/A\")\n",
    "            place_lat = place[\"geometry\"][\"location\"][\"lat\"]\n",
    "            place_lng = place[\"geometry\"][\"location\"][\"lng\"]\n",
    "\n",
    "            # Fetch estimated travel time & distance\n",
    "            travel_time, travel_distance = get_travel_time(lat, lng, place_lat, place_lng)\n",
    "\n",
    "            # Fetch place image if available\n",
    "            if \"photos\" in place:\n",
    "                photo_reference = place[\"photos\"][0][\"photo_reference\"]\n",
    "                image_url = f\"https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference={photo_reference}&key={API_KEY}\"\n",
    "            else:\n",
    "                image_url = None\n",
    "\n",
    "            # Google Maps navigation link\n",
    "            directions_url = f\"https://www.google.com/maps/dir/?api=1&origin={lat},{lng}&destination={place_lat},{place_lng}&travelmode=driving\"\n",
    "\n",
    "            # Format output\n",
    "            place_info = (\n",
    "                f\"üè• **{name}** (Rating: {rating})\\n\"\n",
    "                f\"üöó **Travel Time:** {travel_time} ({travel_distance})\\n\"\n",
    "                f\"[üó∫Ô∏è Get Directions]({directions_url})\"\n",
    "            )\n",
    "            if image_url:\n",
    "                place_info += f\"\\n![{name}]({image_url})\"\n",
    "\n",
    "            place_details.append(place_info)\n",
    "\n",
    "    return f\"üìç **Your Location:** Latitude {lat}, Longitude {lng}\\n\\nüè• **Nearby Medical Facilities:**\\n\" + \"\\n\\n\".join(place_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our tool call function which calls our medical-o1-sft model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medical_responses(response):\n",
    "    \"\"\"Generates a medical response and includes user location, nearby medical places, and images.\"\"\"\n",
    "    \n",
    "    print(\"Using medical-o1-sft AI model...\")\n",
    "    generation_config = {\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.7,\n",
    "        \"top_k\": 50,\n",
    "        \"max_output_tokens\": 8096,\n",
    "    }\n",
    "\n",
    "    model = genai.GenerativeModel(model_name='tunedModels/medicalo1sft-1pua76l6x65r',safety_settings=None, generation_config=generation_config)\n",
    "    medical_result = model.generate_content(response)\n",
    "    medical_text = medical_result.candidates[0].content.parts[0].text\n",
    "\n",
    "    \n",
    "    location_info = get_location_and_places()\n",
    "\n",
    "    return f\"ü©∫ **Medical Response:**\\n{medical_text}\\n\\n{location_info}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definition for tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a particular dictionary structure that's required to describe our function:\n",
    "\n",
    "chat_function = {\n",
    "    \"name\": \"medical_responses\",\n",
    "    \"description\": \"Call this function whenever you want to answer any medical, ethical condition or do not have any information available or cannot give any medical advice about a particular prompt asked by the user in hindi and english or if you do not have access to specific regulations and guidelines or if the user asks to get them to the nearest hospital or hospitals near me or if you cannot give the medical advice, for example when the user asks about some medical conditions, medical scenarios, diseases or tells about his/her symptoms of the disease and also call this function if you cannot give any medical advice. ‡§ú‡§¨ ‡§≠‡•Ä ‡§Ü‡§™ ‡§ï‡§ø‡§∏‡•Ä ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ, ‡§®‡•à‡§§‡§ø‡§ï ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç ‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•á ‡§™‡§æ‡§∏ ‡§ï‡•ã‡§à ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à ‡§Ø‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§î‡§∞ ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§õ‡•á ‡§ó‡§è ‡§ï‡§ø‡§∏‡•Ä ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§∏‡§Ç‡§ï‡•á‡§§ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ï‡•ã‡§à ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§∏‡§≤‡§æ‡§π ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§Ø‡§æ ‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•á ‡§™‡§æ‡§∏ ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§®‡§ø‡§Ø‡§Æ‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§∂‡§æ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§§‡§ï ‡§™‡§π‡•Å‡§Ç‡§ö ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à ‡§Ø‡§æ ‡§Ø‡§¶‡§ø ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§®‡§ø‡§ï‡§ü‡§§‡§Æ ‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤ ‡§Ø‡§æ ‡§Æ‡•á‡§∞‡•á ‡§®‡§ú‡§¶‡•Ä‡§ï ‡§ï‡•á ‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§≤‡•á ‡§ú‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§π‡§§‡§æ ‡§π‡•à ‡§Ø‡§æ ‡§Ø‡§¶‡§ø ‡§Ü‡§™ ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§∏‡§≤‡§æ‡§π ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ú‡§¨ ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡•Å‡§õ ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§∏‡•ç‡§•‡§ø‡§§‡§ø‡§Ø‡•ã‡§Ç, ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø‡•ã‡§Ç, ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§õ‡§§‡§æ ‡§π‡•à ‡§Ø‡§æ ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§≤‡§ï‡•ç‡§∑‡§£‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§Ø‡§¶‡§ø ‡§Ü‡§™ ‡§ï‡•ã‡§à ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§∏‡§≤‡§æ‡§π ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§§‡•ã ‡§≠‡•Ä ‡§á‡§∏ ‡§´‡§º‡§Ç‡§ï‡•ç‡§∂‡§® ‡§ï‡•ã ‡§ï‡•â‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"response\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The symptoms , disease or the medical conditions which is described by the user\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"response\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_function_gemini ={'function_declarations': \n",
    "[\n",
    "{\n",
    "    \"name\": \"medical_responses\",\n",
    "    \"description\": \"Call this function whenever you want to answer any medical, ethical condition or do not have any information available or cannot give any medical advice about a particular prompt asked by the user in any of these languages such as hindi,english,marathi,kannada, or any other languages or if you do not have access to specific regulations and guidelines or if the user asks to get them to the nearest hospital or hospitals near me or if you cannot give the medical advice, for example when the user asks about some medical conditions, medical scenarios, diseases or tells about his/her symptoms of the disease and also call this function if you cannot give any medical advice.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"response\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The symptoms , disease or the medical conditions which is described by the user\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"response\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_med = [{\"type\": \"function\", \"function\": chat_function}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for \"All in one\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_med(message,history):\n",
    "  messages = [{\"role\": \"user\", \"content\": message}]\n",
    "  response = openai.chat.completions.create(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        messages=messages,\n",
    "        tools=tools_med,  \n",
    "      )\n",
    "  try:\n",
    "    if response.choices[0].message.tool_calls[0].function.name == 'medical_responses':\n",
    "      tool_call = response.choices[0].message.tool_calls[0]\n",
    "      arguments = tool_call.function.arguments\n",
    "      c = json.loads(arguments)\n",
    "      med_resp = c.get('response')\n",
    "      result_1 = medical_responses(med_resp)\n",
    "      return result_1           \n",
    "  except:\n",
    "      return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Force tool call for \"Different Language Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai.types import content_types\n",
    "from collections.abc import Iterable\n",
    "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
    "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
    "    return content_types.to_tool_config(\n",
    "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
    "    )\n",
    "\n",
    "available_fns = [\"medical_responses\"]\n",
    "tool_config = tool_config_from_mode(\"any\", available_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_gemini(message, history):\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name='gemini-1.5-flash',\n",
    "        tools= [chat_function_gemini],   \n",
    "    )\n",
    "    chat = model.start_chat()\n",
    "    response =  chat.send_message(message, tool_config=tool_config)\n",
    "    result = response.candidates[0].content.parts[0].function_call.args.get(\"response\")\n",
    "    results = medical_responses(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat function for \"Speech to text\" Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_speech(global_transcription):\n",
    "  messages = [{\"role\": \"user\", \"content\": global_transcription}]\n",
    "  response = openai.chat.completions.create(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        messages=messages,\n",
    "        tools=tools_med,  \n",
    "      )\n",
    "  try:\n",
    "    if response.choices[0].message.tool_calls[0].function.name == 'medical_responses':\n",
    "      tool_call = response.choices[0].message.tool_calls[0]\n",
    "      arguments = tool_call.function.arguments\n",
    "      c = json.loads(arguments)\n",
    "      med_resp = c.get('response')\n",
    "      result_1 = medical_responses(med_resp)\n",
    "      return result_1           \n",
    "  except:\n",
    "      return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to text function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "\n",
    "import gradio as gr\n",
    "import pyaudio\n",
    "from google.cloud import speech\n",
    "\n",
    "# Global variables\n",
    "global_transcription = \"\"\n",
    "stream_active = False\n",
    "\n",
    "# Audio parameters\n",
    "STREAMING_LIMIT = 240000  # 4 minutes\n",
    "SAMPLE_RATE = 16000\n",
    "CHUNK_SIZE = int(SAMPLE_RATE / 10)  # 100ms\n",
    "\n",
    "class ResumableMicrophoneStream:\n",
    "    def __init__(self, rate, chunk_size):\n",
    "        self._rate = rate\n",
    "        self.chunk_size = chunk_size\n",
    "        self._num_channels = 1\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=self._num_channels,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk_size,\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.closed = False\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, *args, **kwargs):\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        while not self.closed:\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            yield chunk\n",
    "\n",
    "\n",
    "def transcribe_audio():\n",
    "    global global_transcription, stream_active\n",
    "    client = speech.SpeechClient()\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=SAMPLE_RATE,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config, interim_results=True\n",
    "    )\n",
    "\n",
    "    with ResumableMicrophoneStream(SAMPLE_RATE, CHUNK_SIZE) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (\n",
    "            speech.StreamingRecognizeRequest(audio_content=content)\n",
    "            for content in audio_generator\n",
    "        )\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "        for response in responses:\n",
    "            if not response.results:\n",
    "                continue\n",
    "\n",
    "            result = response.results[0]\n",
    "            if not result.alternatives:\n",
    "                continue\n",
    "\n",
    "            transcript = result.alternatives[0].transcript.strip()\n",
    "\n",
    "            if result.is_final:\n",
    "                global_transcription += transcript + \" \"\n",
    "                if re.search(r\"\\b(exit|quit)\\b\", transcript, re.I):\n",
    "                    stream_active = False\n",
    "                    break\n",
    "\n",
    "    stream_active = False\n",
    "\n",
    "\n",
    "def start_stream():\n",
    "    global stream_active, global_transcription\n",
    "    global_transcription = \"\" \n",
    "    if not stream_active:\n",
    "        stream_active = True\n",
    "        threading.Thread(target=transcribe_audio, daemon=True).start()\n",
    "    return \"Listening... Say 'Exit' to stop.\"\n",
    "\n",
    "\n",
    "def stop_stream():\n",
    "    global stream_active\n",
    "    stream_active = False\n",
    "    return \"Transcription Stopped.\\nFinal text: \" + global_transcription\n",
    "\n",
    "\n",
    "def reset_transcription():\n",
    "    global global_transcription\n",
    "    global_transcription = \"\"\n",
    "    return \"Transcription reset.\"\n",
    "\n",
    "\n",
    "def view_transcription():\n",
    "    return global_transcription\n",
    "\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def control_stream_(action):\n",
    "    global chat_history, global_transcription, stream_active\n",
    "\n",
    "    if action == \"Start\":\n",
    "        response = start_stream()\n",
    "    elif action == \"Stop\":\n",
    "        response = stop_stream()\n",
    "    elif action == \"Send\":\n",
    "        response = chat_speech(global_transcription)\n",
    "    elif action == \"View\":\n",
    "        response = view_transcription()\n",
    "    else:\n",
    "        response = reset_transcription()\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    return chat_history \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All wrapped in a Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using medical-o1-sft AI model...\n",
      "Using medical-o1-sft AI model...\n",
      "Using medical-o1-sft AI model...\n"
     ]
    }
   ],
   "source": [
    "demo = gr.TabbedInterface(\n",
    "    [\n",
    "        gr.ChatInterface(fn=chat_med, type=\"messages\"),\n",
    "        gr.ChatInterface(fn=chat_gemini, type=\"messages\"),\n",
    "        gr.Interface(\n",
    "            fn=control_stream_,                                                                            \n",
    "            inputs=[gr.Radio([\"Start\", \"Stop\" ,\"View\", \"Reset\", \"Send\"], label=\"Control Streaming\", value=None)],\n",
    "            outputs=gr.Chatbot(type=\"messages\"),\n",
    "            flagging_mode=\"never\"\n",
    "        )\n",
    "    ],\n",
    "    tab_names=[\"All-in-one model\", \"Different Languages model (Beta)\",\"Speech to Text\"],\n",
    "    theme= \"hmb/amethyst\"\n",
    ")\n",
    "\n",
    "demo.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('llmenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96893c8607dc97b003d35d006dea5dda501bef0f0b6219a24909f378e5a45af9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
